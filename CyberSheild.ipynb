{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97ffdf7b-198b-4384-81ee-b2e6ad593812",
      "metadata": {
        "id": "97ffdf7b-198b-4384-81ee-b2e6ad593812"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2d1c82-b572-4c61-a834-741baa9c6d0d",
      "metadata": {
        "id": "8c2d1c82-b572-4c61-a834-741baa9c6d0d",
        "outputId": "718c52c1-09fc-4874-a2cc-6e31e30e14e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text              label\n",
            "0  @ZubearSays Any real nigga isn't letting this ...     ethnicity/race\n",
            "1  @MoradoSkittle @prolifejewess @DAConsult @Kell...  not_cyberbullying\n",
            "2        the only thing i wish, i wish a nigga would     ethnicity/race\n",
            "3  You saudias are not friends of Muslim idiots c...           religion\n",
            "4  @JaydenT2399 @TractorLaw @holmes_gael @erconge...           religion\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99990 entries, 0 to 99989\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    99990 non-null  object\n",
            " 1   label   99990 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.5+ MB\n",
            "None\n",
            "Index(['text', 'label'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('cb_multi_labeled_balanced.csv')\n",
        "\n",
        "# View the first few rows and the structure of the data\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4802584e-848d-45e1-ade4-bf17a6d8a14d",
      "metadata": {
        "id": "4802584e-848d-45e1-ade4-bf17a6d8a14d",
        "outputId": "4fcf8b9c-bd8a-47af-d630-c394b2897cef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\daksh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\daksh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          clean_text\n",
            "0                     real nigga isnt letting happen\n",
            "1  didnt even mention mexico u far safest place e...\n",
            "2                        thing wish wish nigga would\n",
            "3       saudias friend muslim idiot cheapless people\n",
            "4  yet maga want judah christian muslim believe s...\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data (run these once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove @names (mentions)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation and non-alphabetic characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = text.strip()\n",
        "\n",
        "    # Tokenize by splitting on whitespace\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Remove stopwords and lemmatize tokens\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply text cleaning to the 'text' column of your DataFrame\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Inspect the cleaned text\n",
        "print(df[['clean_text']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a95024a1-fd53-4048-a5cd-c573afc1e087",
      "metadata": {
        "id": "a95024a1-fd53-4048-a5cd-c573afc1e087",
        "outputId": "c82e503b-2dc6-45ca-bc32-10d26fff1d22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text          0\n",
            "label         0\n",
            "clean_text    0\n",
            "dtype: int64\n",
            "After cleaning, dataset shape: (99989, 3)\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values in key columns\n",
        "print(df.isnull().sum())\n",
        "\n",
        "df = df.dropna(subset=['text'])\n",
        "\n",
        "# Remove duplicate rows if any\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(\"After cleaning, dataset shape:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b4bafd-f1d1-4ffb-ade7-5aaef33dbcff",
      "metadata": {
        "id": "51b4bafd-f1d1-4ffb-ade7-5aaef33dbcff",
        "outputId": "96f47f96-89cc-4d69-ff35-91d801f8bd6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               label  binary_label\n",
            "0     ethnicity/race             1\n",
            "1  not_cyberbullying             0\n",
            "2     ethnicity/race             1\n",
            "3           religion             1\n",
            "4           religion             1\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Label-encode the multi-class labels\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['label'])\n",
        "\n",
        "# 2. Create a binary label column\n",
        "#    0 -> 'not_cyberbullying'\n",
        "#    1 -> all other labels\n",
        "df['binary_label'] = df['label'].apply(lambda x: 0 if x == 'not_cyberbullying' else 1)\n",
        "\n",
        "# Inspect the results\n",
        "print(df[['label', 'binary_label']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de691d7b-225e-4b66-89f6-582ca3a9c97b",
      "metadata": {
        "id": "de691d7b-225e-4b66-89f6-582ca3a9c97b",
        "outputId": "0c0638e4-4f29-4656-91b2-e3cdd0625d82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                           real nigga isnt letting happen\n",
              "1        didnt even mention mexico u far safest place e...\n",
              "2                              thing wish wish nigga would\n",
              "3             saudias friend muslim idiot cheapless people\n",
              "4        yet maga want judah christian muslim believe s...\n",
              "                               ...                        \n",
              "99985         thank fuck didnt dance remix peru loveisland\n",
              "99986    sierra canyon v alemany california high school...\n",
              "99987                       bitch wasnt flirting snitching\n",
              "99988                                   like yo nigga call\n",
              "99989                                       happy cake day\n",
              "Name: clean_text, Length: 99989, dtype: object"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit and transform the cleaned text data\n",
        "X = vectorizer.fit_transform(df['clean_text'])\n",
        "\n",
        "# Labels\n",
        "y = df['clean_text']\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b8c728d-a63f-47d3-9ff4-d38d7ec87dfe",
      "metadata": {
        "id": "6b8c728d-a63f-47d3-9ff4-d38d7ec87dfe",
        "outputId": "b3840f92-3b41-455b-aec0-c850c39d4cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (79991, 5000)\n",
            "Test set size: (19998, 5000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8e9773d-12ed-4310-bb1d-27c0fd56a999",
      "metadata": {
        "id": "c8e9773d-12ed-4310-bb1d-27c0fd56a999",
        "outputId": "b87927b1-3515-4faf-8aa9-a0595f950185"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>binary_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>real nigga isnt letting happen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>didnt even mention mexico u far safest place e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thing wish wish nigga would</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>saudias friend muslim idiot cheapless people</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yet maga want judah christian muslim believe s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99985</th>\n",
              "      <td>thank fuck didnt dance remix peru loveisland</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99986</th>\n",
              "      <td>sierra canyon v alemany california high school...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99987</th>\n",
              "      <td>bitch wasnt flirting snitching</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99988</th>\n",
              "      <td>like yo nigga call</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99989</th>\n",
              "      <td>happy cake day</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99989 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              clean_text  binary_label\n",
              "0                         real nigga isnt letting happen             1\n",
              "1      didnt even mention mexico u far safest place e...             0\n",
              "2                            thing wish wish nigga would             1\n",
              "3           saudias friend muslim idiot cheapless people             1\n",
              "4      yet maga want judah christian muslim believe s...             1\n",
              "...                                                  ...           ...\n",
              "99985       thank fuck didnt dance remix peru loveisland             0\n",
              "99986  sierra canyon v alemany california high school...             0\n",
              "99987                     bitch wasnt flirting snitching             1\n",
              "99988                                 like yo nigga call             1\n",
              "99989                                     happy cake day             0\n",
              "\n",
              "[99989 rows x 2 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop the columns and create a new DataFrame\n",
        "df_new = df.drop(columns=['text', 'label', 'label_encoded'])\n",
        "\n",
        "# OR drop them in-place (this modifies 'df' directly)\n",
        "df.drop(columns=['text', 'label', 'label_encoded'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9030d556-8fbb-463c-85eb-1eaf2a99dddb",
      "metadata": {
        "id": "9030d556-8fbb-463c-85eb-1eaf2a99dddb",
        "outputId": "e3bd9e5a-f8d1-4799-b524-74d4a6946a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (79991, 5000)\n",
            "Test set size: (19998, 5000)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "58520                                 love hope get chance\n",
              "38239    look know picked lottery number even ticket sa...\n",
              "3806     always sneak charlotte friend call like bitch ...\n",
              "27925    fit ugly hell cant wait yall admit year httpst...\n",
              "6006                   welcome clay farm httpstcoqilkaoian\n",
              "                               ...                        \n",
              "6265                                            yay adding\n",
              "54887    isi savvy social medium bc teacher adam ghadan...\n",
              "76821                          killed dirty hand son bitch\n",
              "860      excellent academic help team essay pay law ess...\n",
              "15795                        bitch liar httpstcokkwiufvcuo\n",
              "Name: clean_text, Length: 79991, dtype: object"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n",
        "X_train\n",
        "\n",
        "y_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ac3716-8a1e-4117-b35c-3a934bd62468",
      "metadata": {
        "id": "50ac3716-8a1e-4117-b35c-3a934bd62468",
        "outputId": "9e79d27d-15f9-4e24-832f-00ebdb4986d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-cyberbullying (0): 49999\n",
            "Cyberbullying (1): 49990\n"
          ]
        }
      ],
      "source": [
        "counts = df['binary_label'].value_counts().to_dict()\n",
        "print(\"Non-cyberbullying (0):\", counts.get(0, 0))\n",
        "print(\"Cyberbullying (1):\", counts.get(1, 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c82aeac0-f76d-4b01-80a9-e51230f14841",
      "metadata": {
        "id": "c82aeac0-f76d-4b01-80a9-e51230f14841",
        "outputId": "faa89b3d-4f96-4ea2-a549-38f4fbbffe05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.9922492249224922\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     10124\n",
            "           1       1.00      0.99      0.99      9874\n",
            "\n",
            "    accuracy                           0.99     19998\n",
            "   macro avg       0.99      0.99      0.99     19998\n",
            "weighted avg       0.99      0.99      0.99     19998\n",
            "\n",
            "[[10114    10]\n",
            " [  145  9729]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "# Load and preprocess your data\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['clean_text'])\n",
        "y = df['binary_label']\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Choose logistic regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "# Evaluation\n",
        "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c316bd0-22dc-4a93-9ee4-f66c968b88c0",
      "metadata": {
        "id": "4c316bd0-22dc-4a93-9ee4-f66c968b88c0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}